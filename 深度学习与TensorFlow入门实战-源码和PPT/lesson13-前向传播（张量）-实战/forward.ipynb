{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forward.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henryji96/TensorFlow-2.x-Tutorials/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8ETensorFlow%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98-%E6%BA%90%E7%A0%81%E5%92%8CPPT/lesson13-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88%E5%BC%A0%E9%87%8F%EF%BC%89-%E5%AE%9E%E6%88%98/forward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5av_qsqmhtQ",
        "colab_type": "code",
        "outputId": "8988511f-c221-45f0-a3b2-b1f0d76e622c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JFrYYKHfRNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import os\n",
        "\n",
        "'''\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='1' # 这是默认的显示等级，显示所有信息\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='2' # 只显示 warning 和 Error \n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='3' # 只显示 Error  \n",
        "'''\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw0Q_bwkmSq4",
        "colab_type": "code",
        "outputId": "e5874e21-f95b-4fe3-d7ee-44e3b57aaa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-beta1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtupFVW47jGd",
        "colab_type": "code",
        "outputId": "c80ffdc3-46ad-43bb-b28c-63e504d2ea48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Is there a GPU available: \", tf.test.is_gpu_available())\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is there a GPU available:  True\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Nz8pjI8x4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.device('device:GPU:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyxHnuycrySk",
        "colab_type": "text"
      },
      "source": [
        "## 1 load mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Zcnzd_r-y4",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCaO0Ytjhpe4",
        "colab_type": "code",
        "outputId": "032246c8-7d50-4945-bb4f-e7ffbc0cb6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# 加载mnist，如果没有缓存则自动下载解析\n",
        "# x: [60k, 28, 28],\n",
        "# y: [60k]\n",
        "(x, y), _ = datasets.mnist.load_data()\n",
        "print(type(x), x.dtype)\n",
        "print(type(y), y.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "<class 'numpy.ndarray'> uint8\n",
            "<class 'numpy.ndarray'> uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-l2PCHusCu3",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 numpy to tensor & normalize x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA1QaJ4_lNjx",
        "colab_type": "code",
        "outputId": "3af47261-919e-428a-f410-fc2b4436dee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# x: [0~255] => [0~1.]\n",
        "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
        "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
        "\n",
        "print(type(x), x.dtype)\n",
        "print(type(y), y.dtype)\n",
        "\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "print(tf.reduce_min(x), tf.reduce_max(x))\n",
        "print(tf.reduce_min(y), tf.reduce_max(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'> <dtype: 'float32'>\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> <dtype: 'int32'>\n",
            "(60000, 28, 28) (60000,)\n",
            "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS6gA1jbsLDY",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 tensor to Dataset instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XomrrUXkhprc",
        "colab_type": "code",
        "outputId": "a87c82cd-5607-4777-c9f8-a580c494a1f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 创建Dataset对象取batch\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
        "\n",
        "# 迭代器\n",
        "train_iter = iter(train_db)\n",
        "sample = next(train_iter) # 取一个batch  batch_size为128\n",
        "print('batch:', sample[0].shape, sample[1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: (128, 28, 28) (128,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLPeLsJsrJ_k",
        "colab_type": "text"
      },
      "source": [
        "## 2 feed forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59rPiTdtjJr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
        "# [dim_in, dim_out], [dim_out]\n",
        "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1)) # std=1时梯度爆炸\n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "\n",
        "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
        "b2 = tf.Variable(tf.zeros([128]))\n",
        "\n",
        "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
        "b3 = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Q67BFLssxs",
        "colab_type": "code",
        "outputId": "a9c9ffcf-c54e-41f4-c17d-98d8866a3f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "lr = 1e-3\n",
        "\n",
        "for epoch in range(2): # iterate whole dataset\n",
        "  for step, (x, y) in enumerate(train_db): # iterate one batch\n",
        "    # h1 = x@w1 + b1\n",
        "    # x - one batch [128, 28, 28]  --> [128, 28*28]\n",
        "    # w1 - [784,256]\n",
        "    # b1 - [256] ==> automatially tf.broadcast_to(b1, [x.shape[0], 256]) ==> [128, 256]\n",
        "\n",
        "    x = tf.reshape(x, [-1, 28*28])\n",
        "\n",
        "    # 参与gradient计算的代码， 构建计算图, watch tf.Variable类型\n",
        "    with tf.GradientTape() as tape:\n",
        "      h1 = x@w1 + b1\n",
        "      h1 = tf.nn.relu(h1)\n",
        "      # [b, 256] ==> [b, 128]\n",
        "      h2 = h1@w2 + b2\n",
        "      h2 = tf.nn.relu(h2)\n",
        "      # [b, 128] ==> [b, 10]\n",
        "      out = h2@w3 + b3\n",
        "\n",
        "      # compute loss\n",
        "      # out: [b, 10]\n",
        "      # y: [b] ==> [b, 10]\n",
        "      y_onehot = tf.one_hot(y, 10)\n",
        "      #mse = mean(sum(y-out)^2)\n",
        "      loss = tf.square(y_onehot - out) # [b, 10]\n",
        "      loss = tf.reduce_mean(loss)    # scalar\n",
        "\n",
        "    # compute gradients\n",
        "    grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
        "\n",
        "    # w1 = w1 - lr*w1_grad   (Variable - Tensor 返回 Tensor, tape无法继续watch)\n",
        "    # assign_sub inplace update, 数据引用保持不变\n",
        "    w1.assign_sub(lr * grads[0])\n",
        "    b1.assign_sub(lr * grads[1])\n",
        "    w2.assign_sub(lr * grads[2])\n",
        "    b2.assign_sub(lr * grads[3])\n",
        "    w3.assign_sub(lr * grads[4])\n",
        "    b3.assign_sub(lr * grads[5])\n",
        "\n",
        "    if step% 100 == 0:\n",
        "      print(\"epoch: {}, step: {}, training loss: {}\".format(epoch, step, float(loss))) # float(loss): tensor to scalar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, step: 0, training loss: 0.5016995668411255\n",
            "epoch: 0, step: 100, training loss: 0.20781607925891876\n",
            "epoch: 0, step: 200, training loss: 0.17083518207073212\n",
            "epoch: 0, step: 300, training loss: 0.16126517951488495\n",
            "epoch: 0, step: 400, training loss: 0.15797080099582672\n",
            "epoch: 1, step: 0, training loss: 0.16217073798179626\n",
            "epoch: 1, step: 100, training loss: 0.1532837152481079\n",
            "epoch: 1, step: 200, training loss: 0.13839606940746307\n",
            "epoch: 1, step: 300, training loss: 0.13728100061416626\n",
            "epoch: 1, step: 400, training loss: 0.136625736951828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ChirTx_8fhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}